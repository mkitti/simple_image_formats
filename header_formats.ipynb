{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dfbfb01-22b9-4306-84ea-fe5ffd6db371",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "\n",
    "![Situation: There are 14 competing standards. 14?! Ridiculous! We need develop one universal standard that covers everyone's use cases. Yeah! Soon, Situation: There are 15 competing standards. From https://imgs.xkcd.com/comics/standards.png](images/standards.png)\n",
    "\n",
    "CC BY-NC 2.5 https://xkcd.com/927\n",
    "\n",
    "\n",
    "\"Situation: There are 3 competing standards\" the last card of a popular XKCD cartoon (#927) might read if applied to recent microscopy bioimaging formats. TIFF, HDF5, and Zarr have all been used to store images as part of popular standards and formats (OME-TIFF, BDV-HDF5, OME-Zarr). The cartoon humorously points out the tendency to create new standards while discounting prior efforts. To combat the proliferation of formats I examine similarities between TIFF, HDF5, and Zarr shard containers. I then exploit them to create a combined data container that is simultaneously a TIFF file, a HDF5 file, and a Zarr version 3 shard without duplicating the image pixel or volumetric voxel data. This combined format is compatible with multiple viewers and image analysis pipelines. Additionally, the techniques involved provide a path to convert between the formats with minimal processing or overhead. In practice, the combined format avoids redundant copies of data while providing great utility to the microscope user. The combined format is a great candidate for a microscope acquisition format as it satisfies both short term needs to view microscope output in traditional viewers while integrating into next generation image analysis pipelines.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f012b74-35b7-4122-8da9-10ee102fa0b9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "![](images/01_cloud_optimized_file_formats.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2ddaaa-5d84-4c71-a037-a73016a1a66b",
   "metadata": {},
   "source": [
    "![](images/02_binary_templates.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90a91f1-acb7-4ec2-81eb-e426d3c2298e",
   "metadata": {},
   "source": [
    "![Implemtation Outline](images/03_implementation_outline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166121d2-1886-4447-b389-0c37a2a47f89",
   "metadata": {},
   "source": [
    "## 1. Write the Combined File Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d678403-7ae3-4043-8752-fdb131e7dd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import header_formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4577b8c2-d1c2-4e8b-a01a-9468602fcbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "def run_demo():\n",
    "    # create a template file\n",
    "    header_formats.tiff_hdf5_zarr(\"test.tiff.hdf5.zarr\", (256,256), \"uint16\", chunks=(128,128))\n",
    "    header_formats.create_zarr3(\"demo/test.zarr\")\n",
    "\n",
    "    # extract header and footer from template\n",
    "    header, footer = header_formats.read_header_footer(\"test.tiff.hdf5.zarr\")\n",
    "\n",
    "    # create chunks\n",
    "    A = np.full((128, 128), 0, dtype=\"uint16\") \n",
    "    B = np.full((128, 128), 2**14-2, dtype=\"uint16\")\n",
    "    C = np.full((128, 128), 2*2**14-2, dtype=\"uint16\")\n",
    "    D = np.full((128, 128), 3*2**14-2, dtype=\"uint16\")    \n",
    "\n",
    "    os.makedirs(\"demo/test.zarr/c/0/\")\n",
    "\n",
    "    # write header, tiles and footer to demo file\n",
    "    with open(\"demo/demo.hdf5.zarr.tiff\", \"wb\") as f:\n",
    "        f.write(header)\n",
    "        f.write(A)\n",
    "        f.write(B)\n",
    "        f.write(C)\n",
    "        f.write(D)\n",
    "        f.write(footer)\n",
    "\n",
    "    # copy one file to many files with different file extensions\n",
    "    # TIFF\n",
    "    shutil.copyfile(\"demo/demo.hdf5.zarr.tiff\", \"demo/demo.tiff\")\n",
    "    # HDF5\n",
    "    shutil.copyfile(\"demo/demo.hdf5.zarr.tiff\", \"demo/demo.h5\")\n",
    "    # Zarr v3 shard\n",
    "    shutil.copyfile(\"demo/demo.hdf5.zarr.tiff\", \"demo/test.zarr/c/0/0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e106ce68-a2d7-4876-b4e0-7679a9db9922",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MissingRequired: TIFF directory is missing required \"TileOffsets\" field.\n",
      "MissingRequired: TIFF directory is missing required \"TileOffsets\" field.\n"
     ]
    }
   ],
   "source": [
    "run_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cebe9f-89c0-43cf-8905-b941f66acb0c",
   "metadata": {},
   "source": [
    "## 2. Check the HDF5 and TIFF File Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aad0f154-c877-4a16-bc7f-ced54f93350e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2KOpened \"demo/demo.hdf5.zarr.tiff\" with sec2 driver.                                      \n",
      "data                     Dataset {256/256, 256/256}\n",
      "    Location:  1:195\n",
      "    Links:     1\n",
      "    Modified:  2025-10-03 19:17:20 EDT\n",
      "    Chunks:    {128, 128} 32768 bytes\n",
      "    Storage:   131072 logical bytes, 131072 allocated bytes, 100.00% utilization\n",
      "    Type:      native unsigned short\n",
      "    Address: 2048\n",
      "           Flags    Bytes     Address          Logical Offset\n",
      "        ========== ======== ========== ==============================\n",
      "        0x00000000    32768       2048 [0, 0, 0]\n",
      "        0x00000000    32768      34816 [0, 128, 0]\n",
      "        0x00000000    32768      67584 [128, 0, 0]\n",
      "        0x00000000    32768     100352 [128, 128, 0]\n",
      "zarrindex                Dataset {68/68}\n",
      "    Location:  1:479\n",
      "    Links:     1\n",
      "    Storage:   68 logical bytes, 68 allocated bytes, 100.00% utilization\n",
      "    Type:      native unsigned char\n",
      "    Address:   133120\n"
     ]
    }
   ],
   "source": [
    "!pixi run h5ls -va demo/demo.hdf5.zarr.tiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89c09548-d772-4cd6-95da-744013d3f315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K=== TIFF directory 0 ===vironment                                                        \n",
      "TIFF Directory at offset 0x86 (134)\n",
      "  Image Width: 256 Image Length: 256\n",
      "  Tile Width: 128 Tile Length: 128\n",
      "  Bits/Sample: 16\n",
      "  Sample Format: unsigned integer\n",
      "  Compression Scheme: None\n",
      "  Photometric Interpretation: min-is-black\n",
      "  Orientation: row 0 top, col 0 lhs\n",
      "  Planar Configuration: single image plane\n",
      "  4 Tiles:\n",
      "      0: [    3072,    32768]\n",
      "      1: [   35840,    32768]\n",
      "      2: [   68608,    32768]\n",
      "      3: [  101376,    32768]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pixi run tiffinfo -s demo/demo.hdf5.zarr.tiff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dc8d3f-a451-4d13-8b5d-0b8f71f144c8",
   "metadata": {},
   "source": [
    "## 3. Read the Data using h5py, libtiff, and tensorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0902a608-84a7-43fb-88ad-620aefd30663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ..., 16382, 16382, 16382],\n",
       "       [    0,     0,     0, ..., 16382, 16382, 16382],\n",
       "       [    0,     0,     0, ..., 16382, 16382, 16382],\n",
       "       ...,\n",
       "       [32766, 32766, 32766, ..., 49150, 49150, 49150],\n",
       "       [32766, 32766, 32766, ..., 49150, 49150, 49150],\n",
       "       [32766, 32766, 32766, ..., 49150, 49150, 49150]],\n",
       "      shape=(256, 256), dtype=uint16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py\n",
    "with h5py.File(\"demo/demo.hdf5.zarr.tiff\") as h5f:\n",
    "    h5data = h5f[\"data\"][:]\n",
    "\n",
    "h5data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26643c11-2321-4c2f-a5d2-e0ab0c8aedb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ..., 16382, 16382, 16382],\n",
       "       [    0,     0,     0, ..., 16382, 16382, 16382],\n",
       "       [    0,     0,     0, ..., 16382, 16382, 16382],\n",
       "       ...,\n",
       "       [32766, 32766, 32766, ..., 49150, 49150, 49150],\n",
       "       [32766, 32766, 32766, ..., 49150, 49150, 49150],\n",
       "       [32766, 32766, 32766, ..., 49150, 49150, 49150]],\n",
       "      shape=(256, 256), dtype=uint16)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from libtiff import TIFF\n",
    "tif = TIFF.open(\"demo/demo.hdf5.zarr.tiff\", \"r\")\n",
    "tiff_data = tif.read_image()\n",
    "tif.close()\n",
    "tiff_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f78e87b2-033b-4952-89ec-9ecd65af6175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ..., 16382, 16382, 16382],\n",
       "       [    0,     0,     0, ..., 16382, 16382, 16382],\n",
       "       [    0,     0,     0, ..., 16382, 16382, 16382],\n",
       "       ...,\n",
       "       [32766, 32766, 32766, ..., 49150, 49150, 49150],\n",
       "       [32766, 32766, 32766, ..., 49150, 49150, 49150],\n",
       "       [32766, 32766, 32766, ..., 49150, 49150, 49150]],\n",
       "      shape=(256, 256), dtype=uint16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorstore as ts\n",
    "ts.open({\n",
    "    \"driver\": \"zarr3\",      \n",
    "    \"kvstore\": {\n",
    "       \"driver\": \"file\",   \n",
    "       \"path\": \"demo/test.zarr/\"\n",
    "    },\n",
    "}).result().read().result() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15f8616c-5e94-4e8f-b6aa-8043699afcd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3072,  32768],\n",
       "       [ 35840,  32768],\n",
       "       [ 68608,  32768],\n",
       "       [101376,  32768]], dtype=uint64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py\n",
    "with h5py.File(\"demo/demo.hdf5.zarr.tiff\") as h5f:\n",
    "    h5data = h5f[\"data\"][:]\n",
    "    h5zarrindex = h5f[\"zarrindex\"][:]\n",
    "    offsets_and_bytes = header_formats.get_hdf5_chunk_offsets_and_bytes(h5f[\"data\"])\n",
    "\n",
    "h5zarrindex[0:-4].view(np.uint64)\n",
    "offsets_and_bytes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bc0220-cb36-4299-91e1-071a4a7cfa15",
   "metadata": {},
   "source": [
    "## 4. Rewrite the data using h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09138fe8-f2fe-4701-964a-135ad2590a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'demo/test.zarr/c/0/0'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py\n",
    "import shutil\n",
    "with h5py.File(\"demo/demo.hdf5.zarr.tiff\", \"r+\") as h5f:\n",
    "    h5f[\"data\"][:128,:128] = 1\n",
    "    h5f[\"data\"][:128,128:] = 2\n",
    "    h5f[\"data\"][128:,:128] = 3\n",
    "    h5f[\"data\"][128:,128:] = 4\n",
    "    \n",
    "# copy to the zarr shard, consider a symlink on Linux systems\n",
    "shutil.copyfile(\"demo/demo.hdf5.zarr.tiff\", \"demo/test.zarr/c/0/0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7c9d51-0ae4-435b-a160-8514c838cc99",
   "metadata": {},
   "source": [
    "## 5. Read the updated data using h5py, libtiff, and tensorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac873653-2113-4b22-b7d9-0d4a97879c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 ... 2 2 2]\n",
      " [1 1 1 ... 2 2 2]\n",
      " [1 1 1 ... 2 2 2]\n",
      " ...\n",
      " [3 3 3 ... 4 4 4]\n",
      " [3 3 3 ... 4 4 4]\n",
      " [3 3 3 ... 4 4 4]]\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(\"demo/demo.hdf5.zarr.tiff\") as h5f:\n",
    "    print(h5f[\"data\"][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e7a9049-13ae-4c0a-baee-67db345f40e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 ... 2 2 2]\n",
      " [1 1 1 ... 2 2 2]\n",
      " [1 1 1 ... 2 2 2]\n",
      " ...\n",
      " [3 3 3 ... 4 4 4]\n",
      " [3 3 3 ... 4 4 4]\n",
      " [3 3 3 ... 4 4 4]]\n"
     ]
    }
   ],
   "source": [
    "tif = TIFF.open(\"demo/demo.hdf5.zarr.tiff\", \"r\")\n",
    "print(tif.read_image())\n",
    "tif.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "277f8856-8320-463c-9ded-49e4f9a6527c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 2, 2, 2],\n",
       "       [1, 1, 1, ..., 2, 2, 2],\n",
       "       [1, 1, 1, ..., 2, 2, 2],\n",
       "       ...,\n",
       "       [3, 3, 3, ..., 4, 4, 4],\n",
       "       [3, 3, 3, ..., 4, 4, 4],\n",
       "       [3, 3, 3, ..., 4, 4, 4]], shape=(256, 256), dtype=uint16)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.open({\n",
    "    \"driver\": \"zarr3\",      \n",
    "    \"kvstore\": {\n",
    "       \"driver\": \"file\",   \n",
    "       \"path\": \"demo/test.zarr/\"\n",
    "    },\n",
    "}).result().read().result() "
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Mark Kittisopikul"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "title": "Combining TIFF, HDF5, and Zarr into a Single Image File Format"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
